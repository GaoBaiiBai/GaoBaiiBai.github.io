<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>海苔船港</title>
  
  <subtitle>参加比赛.认真准备.自己很菜.去喊口号.内心空洞.我是菜🐔.别吹了。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://gaobaiibai.com/"/>
  <updated>2020-03-23T06:10:54.000Z</updated>
  <id>http://gaobaiibai.com/</id>
  
  <author>
    <name>GaoBaiiBai</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>WebScraper</title>
    <link href="http://gaobaiibai.com/2020/03/23/WebScraper/"/>
    <id>http://gaobaiibai.com/2020/03/23/WebScraper/</id>
    <published>2020-03-23T06:10:54.000Z</published>
    <updated>2020-03-23T06:10:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>这里给大家推荐一个非常好用的谷歌爬虫得插件叫做WebScraper，这是一款可以用于爬取规则网站的工具，本篇文章将会对WebScraper的安装与操作等多个方面对其进行介绍。你可以不需要知道爬虫的知识点，爬虫的代码撰写，就可以爬取较为规则的网站。</p><a id="more"></a><h3 id="一、安装说明"><a href="#一、安装说明" class="headerlink" title="一、安装说明"></a>一、安装说明</h3><p>首先我们需要安装Chrome浏览器，打开谷歌的应用去安装WebScraper，当然需要科学上网才可能完成。如果，确实没有科学上网的话，推荐大家安装一款名叫&lt;&lt;极速浏览器&gt;&gt;的浏览器，该款浏览器是具备了谷歌里的内核系统，同时可以下载谷歌里的插件。<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%871.png" alt><br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%872.png" alt></p><h3 id="二、演示实例"><a href="#二、演示实例" class="headerlink" title="二、演示实例"></a>二、演示实例</h3><ul><li><ol><li>网站选择与设置<br>本文用爬取缤客的酒店信息作为演示，百度搜索缤客的页面<a href="https://www.booking.com/" target="_blank" rel="noopener">https://www.booking.com/</a>目的地我们可以选择成都。对于kin缤客的网站我们是需要设置入住日期的，同时为了减小爬取的量我们选择离市中心5公里内的。<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%873.png" alt></li></ol></li><li><ol start="2"><li>WebScraper创建<br>按住F12，选择WebScraper中的Create Sitemap<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%874.png" alt><br>创建Sitemap name和Start URL<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%875.png" alt></li></ol></li><li><ol start="3"><li>WebScraper属性创建<br>选择Add new selector，Type选择Element click，Id我们输入Info Element,Selector选择每一个属性实例图如下：（其中Type Element click的意思是选择每一个属性块，并且可以进行点击翻页；Element scroll down的意思是选择每一个属性快，并且可以进行下滑;Text为内容；Link为链接）<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%876.png" alt><br>选择Click selector中的Select，选择页底的页面翻译，从而进行翻页<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%877.png" alt><br>勾选Multiple，设置Delay (ms)为200<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%878.png" alt><br>创建成功！</li></ol></li><li><ol start="4"><li>WebScraper单个属性创建<br>选择酒店的名称<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%879.png" alt><br>选择价格<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%8710.png" alt><br>选择评分<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%8711.png" alt></li></ol></li><li><ol start="5"><li>WebScraper完成爬取<br>选择Sitemap binkeinfo中的scrape，开始爬取<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%8712.png" alt><br>爬取开始<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%8713.png" alt><br>数据获取完成<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%8714.png" alt><br>选择Sitemap binkeinfo中的Export data as csv导出成为csv模式<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%8715.png" alt><br>数据内容如下，完成爬取<br><img src="/2020/03/23/WebScraper/%E5%9B%BE%E7%89%8716.png" alt></li></ol></li></ul><h3 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h3><p>本文所讲内容有限，并不能全部细讲，只能讲述一个案例来说明WebScraper的功能，如果想更深入的学习Scraper工具可以搜索<a href="https://search.bilibili.com/all?keyword=web%20scraper" target="_blank" rel="noopener">https://search.bilibili.com/all?keyword=web%20scraper</a>内的内容进行深入的学习。转载请注明出处，禁止一切商业用途，目的：仅供学习。欢迎各位大佬指正错误，有问题请在下方留言，或者点击左边的微信/QQ加我进行联系。看到后会第一时间进行回复。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里给大家推荐一个非常好用的谷歌爬虫得插件叫做WebScraper，这是一款可以用于爬取规则网站的工具，本篇文章将会对WebScraper的安装与操作等多个方面对其进行介绍。你可以不需要知道爬虫的知识点，爬虫的代码撰写，就可以爬取较为规则的网站。&lt;/p&gt;
    
    </summary>
    
    
      <category term="爬虫" scheme="http://GaoBaiiBai.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="爬虫" scheme="http://GaoBaiiBai.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="工具" scheme="http://GaoBaiiBai.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Git+GitHub+TortoiseGit间的操作使用</title>
    <link href="http://gaobaiibai.com/2020/03/02/Github_Wugui/"/>
    <id>http://gaobaiibai.com/2020/03/02/Github_Wugui/</id>
    <published>2020-03-02T12:35:18.000Z</published>
    <updated>2020-03-02T12:35:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>近几次发现很多人在使用Git的过程中是通过使用Git的命令进行文件的上传与下载的，所以，就想在这里推荐一款集成了Git命令的图形化软件，从而省下敲命令与思考的时间，更加人性化的图形界面更方便进行操作。个人认为重复的过程是不需要一直重复进行操作的，利用节省下来的时间做更多的事情不是更好吗？本文对TortoiseGit的常用功能进行了叙述与演示。</p><a id="more"></a><p>下面是本文共享出来的安装链接：<a href="https://pan.baidu.com/s/1ek8Uc64-hMU74WkAJ7SI4Q" target="_blank" rel="noopener">https://pan.baidu.com/s/1ek8Uc64-hMU74WkAJ7SI4Q</a> 提取码：6omn</p><h2 id="1-Git与SVN的区别"><a href="#1-Git与SVN的区别" class="headerlink" title="1. Git与SVN的区别"></a>1. Git与SVN的区别</h2><ul><li><ol><li><strong>SVN</strong></li></ol></li><li><strong>SVN</strong>是集中式版本控制系统，版本库是集中放在中央服务器的，而干活的时候，用的都是自己的电脑，所以首先要从中央服务器哪里得到最新的版本，然后干活，干完后，需要把自己做完的活推送到中央服务器。集中式版本控制系统是必须联网才能工作，如果在局域网还可以，带宽够大，速度够快，如果在互联网下，如果网速慢的话，就郁闷了。而SVN的缺点也是很明显的，如果服务器单点故障那么就太恼火了瞬间就感觉要GG了，所以容错性差。</li><li><ol start="2"><li><strong>Git</strong></li></ol></li><li><strong>Git</strong>是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库，这样，工作的时候就不需要联网了，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，那多个人如何协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这时，你们两之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。下图是Git的工作流程<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%871.png" alt></li></ul><h2 id="2-TortoiseGit的使用"><a href="#2-TortoiseGit的使用" class="headerlink" title="2. TortoiseGit的使用"></a>2. TortoiseGit的使用</h2><ul><li><ol><li>TortoiseGit的安装<br>本篇文章不重点讲TortoiseGit的安装了，在上面已经分享过了安装包，直接进行傻瓜式安装就可以了，但是在那之前一定要下载Git，如果出现什么问题的话可以直接进行百度，TortoiseGit是非常优秀的开源的版本库客户端，如果熟练使用的话可以节约很多的时间。</li></ol></li><li><ol start="2"><li>创建版本库<br>在Git中我们可以直接在当前目录下运行Git Bash Here使用git init进行创建，而在TortoiseGit中也是非常的好用，首先我们现在目录下创一个文件test。<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%872.png" alt><br>然后进入文件夹，在空列表中点击右键Git在这里创建版本库，然后就会出现.git文件<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%873.png" alt><br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%874.png" alt></li></ol></li><li><ol start="3"><li>文件提交至本地库<br>我们先创建创建一个测试的txt文件，然后右键点击选中TortoiseGit点击添加，之后成功添加。鼠标选中选择提交，在日至文件中输入修改的内容（必须填写），然后成功提交<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%875.png" alt><br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%876.png" alt><br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%877.png" alt></li></ol></li><li><ol start="4"><li>文件修改、查看修改历史、差异比较<br>我们对txt里面的内容进行修改后txt文件左边会出现感叹号，也就是说明我们已经与本地仓库里的文件内容不同了所以，我们再次重新的重复3的过程，将新的文件推送进本地仓库内。填写日志信息，进行提交。<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%878.png" alt><br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%879.png" alt><br>选择txt文件选择显示日志信息<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8710.png" alt><br>选择txt文件选择与上一版进行比较<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8711.png" alt><br>选择txt文件选择显示日志信息，选择以前要变更的信息，右键重置到这个版本，打开更新后的文件会发现已经没有更新到前面的版本了<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8712.png" alt></li></ol></li><li><ol start="5"><li>删除文件与还原文件<br>选择要删除的内容右键选择删除，至此本地仓库中没有了文件<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8713.png" alt><br>右键选择TortoiseGit-&gt;还原<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8714.png" alt></li></ol></li></ul><h2 id="3-TortoiseGit与Github结合使用"><a href="#3-TortoiseGit与Github结合使用" class="headerlink" title="3.TortoiseGit与Github结合使用"></a>3.TortoiseGit与Github结合使用</h2><p><strong>TortoiseGit的推送</strong></p><ul><li><ol><li>TortoiseGit的本地仓库的导入<br>首先你需要在Github上创建仓库，然后获得到HTTPS或者SSH，例如是使用的HTTPS的仓库为<a href="https://github.com/GaoBaiiBai/Algorithm-learning-content.git" target="_blank" rel="noopener">https://github.com/GaoBaiiBai/Algorithm-learning-content.git</a>，然后我们将本地仓库里添加两个要上传的代码文件夹<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8715.png" alt></li></ol></li><li><ol start="2"><li>TortoiseGit与Github的连接<br>我们可以在文件夹内选择同步然后设置远端，这里我使用的是HTTPS进行的演示，如果你要是用SSH就直接生成密钥的时候设置进Putty密钥即可。<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8716.png" alt><br>至此我们已经与远程仓库之间构建了联系</li></ol></li><li><ol start="3"><li>TortoiseGit推送至Github<br>在文件夹中右键选择Git同步<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8717.png" alt><br>在传输的过程中如果是使用HTTPS的只要输入自己的Github的账号和密码即可。<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8718.png" alt><br>这样一来即推送成功了！<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8719.png" alt></li></ol></li></ul><p><strong>TortoiseGit的拉取</strong><br>直接在Git中选中TortoiseGit，拉取-&gt;选择需要拉取的内容是分支或者是主支<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8720.png" alt></p><p><strong>TortoiseGit的克隆</strong><br>如果想直接clone别人Github上的文件，先创建一个文件夹，右键选择Git克隆<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8721.png" alt><br>输入相应的url<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8722.png" alt><br>fork成功<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8723.png" alt></p><p><strong>使用TortoiseGit实现分支管理</strong></p><ul><li><ol><li>分支的创建<br>右键选择TortoiseGit-&gt;创建分支-&gt;输入分支名字<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8724.png" alt><br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8725.png" alt></li></ol></li><li><ol start="2"><li>分支的合并<br>右键选择TortoiseGit-&gt;分支合并-&gt;选择分支<br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8726.png" alt><br><img src="/2020/03/02/Github_Wugui/%E5%9B%BE%E7%89%8727.png" alt></li></ol></li><li><ol start="3"><li>备注<br>两个分支中编辑的内容都是相互独立互不干扰的，那么如果在两个分支中都对同一个文件进行编辑，然后再合并，就有可能会出现冲突。要先对一个文件进行编辑过后提交至版本库，再对另一个文件进行编辑提交至版本库，最后进行分支合并，出现版本冲突，冲突需要手动解决。在冲突文件上单机右键选择“解决冲突”菜单项，再进行提交即可。</li></ol></li></ul><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h2><p>TortoiseGit的使用还有很多，本文只是较为重点的功能进行了说明，当有其他需求的时候可以右键查看TortoiseGit图形工具，因为是图形化的界面有些功能就可以直接看见，非常方便。最后：转载请注明出处，禁止一切商业用途，目的：仅供学习，欢迎各位大佬指正错误，有问题请在下方留言，或者点击左边的微信/QQ加我进行联系。看到后会第一时间进行回复。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近几次发现很多人在使用Git的过程中是通过使用Git的命令进行文件的上传与下载的，所以，就想在这里推荐一款集成了Git命令的图形化软件，从而省下敲命令与思考的时间，更加人性化的图形界面更方便进行操作。个人认为重复的过程是不需要一直重复进行操作的，利用节省下来的时间做更多的事情不是更好吗？本文对TortoiseGit的常用功能进行了叙述与演示。&lt;/p&gt;
    
    </summary>
    
    
      <category term="工具" scheme="http://GaoBaiiBai.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="http://GaoBaiiBai.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="Git" scheme="http://GaoBaiiBai.com/tags/Git/"/>
    
      <category term="TortoiseGit" scheme="http://GaoBaiiBai.com/tags/TortoiseGit/"/>
    
  </entry>
  
  <entry>
    <title>用Python爬虫实现翻译功能</title>
    <link href="http://gaobaiibai.com/2020/03/02/Pachong_Fanyi/"/>
    <id>http://gaobaiibai.com/2020/03/02/Pachong_Fanyi/</id>
    <published>2020-03-02T12:35:18.000Z</published>
    <updated>2020-03-02T12:35:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>写这篇文档的主要初衷是因为：因为前几天的美赛，由于我们要通过评论的内容找到该评论的情感倾向，但是由于Excel内的翻译功能支持不了大规模的数据进行翻译，然后其他的一些在线翻译的软件需要付费，所以自己写了一个端口用于翻译。（本篇文章内容的翻译仅支持小规模数据，做到及翻及储，大规模数模进行多次翻译还是会出现无连接的情况）</p><a id="more"></a><h3 id="一、文章说明"><a href="#一、文章说明" class="headerlink" title="一、文章说明"></a>一、文章说明</h3><p>一开始在Github上找能对Excel进行翻译的时候发现了一篇通过爬虫实现翻译的源码，然而我并没有看里面的内容，就直接进行运行，导致因为访问频率过快导致直接被谷歌直接封掉了端口，所以以下的内容都是基于<strong>有道翻译</strong>    的翻译进行端口的实现。（非常感谢我某位朋友给我找的Github上的源码使得我比赛期间的谷歌端口一直不能使用）</p><h3 id="二、端口分析"><a href="#二、端口分析" class="headerlink" title="二、端口分析"></a>二、端口分析</h3><ul><li><ol><li>首先我们先打开有道翻译的界面，按住F12（建议使用谷歌浏览器），选择XHR<br><img src="/2020/03/02/Pachong_Fanyi/%E5%9B%BE%E7%89%871.png" alt></li></ol></li><li><ol start="2"><li>在请输入你要翻译的文字或网址内输入要翻译的内容<br><img src="/2020/03/02/Pachong_Fanyi/%E5%9B%BE%E7%89%872.png" alt></li></ol></li><li><ol start="3"><li>分析网址与请求<br>其中请求的网址为：<a href="http://fanyi.youdao.com/translate_o?smartresult=dict&amp;smartresult=rule，我们可以发现其中的smartresult=dict这一段话才是传输的数据，并且数据是以dict的方式进行存储并传输过去的。" target="_blank" rel="noopener">http://fanyi.youdao.com/translate_o?smartresult=dict&amp;smartresult=rule，我们可以发现其中的smartresult=dict这一段话才是传输的数据，并且数据是以dict的方式进行存储并传输过去的。</a><br><img src="/2020/03/02/Pachong_Fanyi/%E5%9B%BE%E7%89%873.png" alt></li></ol></li><li><ol start="4"><li>分析FromData的表单格式<br>我们可以发现表单中的i对应的key的值就是我们输入的翻译的内容<br><img src="/2020/03/02/Pachong_Fanyi/%E5%9B%BE%E7%89%874.png" alt><h3 id="三、代码的撰写"><a href="#三、代码的撰写" class="headerlink" title="三、代码的撰写"></a>三、代码的撰写</h3></li></ol></li><li><ol><li>首先要导入代码的必要请求头<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure></li></ol></li><li><ol start="2"><li>构造请求头<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fanyi</span><span class="params">(key)</span>:</span></span><br><span class="line">    url =  <span class="string">"http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule"</span></span><br><span class="line">    agent1 = <span class="string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36"</span></span><br><span class="line">    agent2 = <span class="string">"Mozilla/5.0 (iPad; CPU OS 5_0 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A334 Safari/7534.48.3"</span></span><br><span class="line">    agent3 = <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64; rv:21.0) Gecko/20100101 Firefox/21.0"</span></span><br><span class="line">    agent4 = <span class="string">"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727"</span></span><br><span class="line">    agent_list = [agent1,agent2,agent3,agent4]</span><br><span class="line">    agent = random.choice(agent_list)</span><br><span class="line">    header = &#123;<span class="string">"User-Agent"</span>:agent&#125;</span><br><span class="line">    <span class="comment"># post请求需要提交的数据</span></span><br><span class="line">    formdata = &#123;</span><br><span class="line">        <span class="string">"i"</span>: key,</span><br><span class="line">        <span class="string">"from"</span>: <span class="string">"AUTO"</span>,</span><br><span class="line">        <span class="string">"to"</span>: <span class="string">"AUTO"</span>,</span><br><span class="line">        <span class="string">"smartresult"</span>: <span class="string">"dict"</span>,</span><br><span class="line">        <span class="string">"client"</span>: <span class="string">"fanyideskweb"</span>,</span><br><span class="line">        <span class="string">"salt"</span>: <span class="string">"15695898180107"</span>,</span><br><span class="line">        <span class="string">"sign"</span>: <span class="string">"bf4bfe3da1f8eb780b6f45cfd226e3e0"</span>,</span><br><span class="line">        <span class="string">"ts"</span>: <span class="string">"1569589818010"</span>,</span><br><span class="line">        <span class="string">"bv"</span>: <span class="string">"97ba7c7fb78632ae9b11dcf6be726aee"</span>,</span><br><span class="line">        <span class="string">"doctype"</span>: <span class="string">"json"</span>,</span><br><span class="line">        <span class="string">"version"</span>: <span class="string">"2.1"</span>,</span><br><span class="line">        <span class="string">"keyfrom"</span>: <span class="string">"fanyi.web"</span>,</span><br><span class="line">        <span class="string">"action"</span>: <span class="string">"FY_BY_REALTlME"</span>,</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><ol start="3"><li>发送Post请求并用re表达式提取信息<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">response = requests.post(url=url,headers = header,data=formdata).content.decode()</span><br><span class="line"><span class="comment"># "tgt":"hello"</span></span><br><span class="line">pat1=re.compile(<span class="string">'"tgt":"(.*?)"'</span>)</span><br><span class="line">data = pat1.findall(response)</span><br><span class="line">str1=<span class="string">""</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">    str1+=i</span><br><span class="line"><span class="keyword">return</span> str1</span><br></pre></td></tr></table></figure></li></ol></li><li><ol start="4"><li>本篇文章使用的数据说明<br><img src="/2020/03/02/Pachong_Fanyi/%E5%9B%BE%E7%89%875.png" alt><br>我们主要是进行翻译review_headline和review_body的这两列信息，同时本篇文章的数据是用UTF-8 模式进行保存的csv数据。并且由于一段时间内可能存在无连接请求的可能加入了时间间隔为1s，由于可能出现一端无连接的情况，都是在翻译完成以后立刻进行保存。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    data = pd.read_csv(<span class="string">"./microwave.csv"</span>, encoding=<span class="string">'UTF-8'</span>, error_bad_lines=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> data.review_headline:</span><br><span class="line">        info = fanyi(i)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">"./microwave.txt"</span>,<span class="string">'a+'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(str(info)+<span class="string">'\n'</span>)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="四、代码合集"><a href="#四、代码合集" class="headerlink" title="四、代码合集"></a>四、代码合集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fanyi</span><span class="params">(key)</span>:</span></span><br><span class="line">    url =  <span class="string">"http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule"</span></span><br><span class="line">    agent1 = <span class="string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36"</span></span><br><span class="line">    agent2 = <span class="string">"Mozilla/5.0 (iPad; CPU OS 5_0 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A334 Safari/7534.48.3"</span></span><br><span class="line">    agent3 = <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64; rv:21.0) Gecko/20100101 Firefox/21.0"</span></span><br><span class="line">    agent4 = <span class="string">"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727"</span></span><br><span class="line">    agent_list = [agent1,agent2,agent3,agent4]</span><br><span class="line">    agent = random.choice(agent_list)</span><br><span class="line">    header = &#123;<span class="string">"User-Agent"</span>:agent&#125;</span><br><span class="line">    <span class="comment"># post请求需要提交的数据</span></span><br><span class="line">    formdata = &#123;</span><br><span class="line">        <span class="string">"i"</span>: key,</span><br><span class="line">        <span class="string">"from"</span>: <span class="string">"AUTO"</span>,</span><br><span class="line">        <span class="string">"to"</span>: <span class="string">"AUTO"</span>,</span><br><span class="line">        <span class="string">"smartresult"</span>: <span class="string">"dict"</span>,</span><br><span class="line">        <span class="string">"client"</span>: <span class="string">"fanyideskweb"</span>,</span><br><span class="line">        <span class="string">"salt"</span>: <span class="string">"15695898180107"</span>,</span><br><span class="line">        <span class="string">"sign"</span>: <span class="string">"bf4bfe3da1f8eb780b6f45cfd226e3e0"</span>,</span><br><span class="line">        <span class="string">"ts"</span>: <span class="string">"1569589818010"</span>,</span><br><span class="line">        <span class="string">"bv"</span>: <span class="string">"97ba7c7fb78632ae9b11dcf6be726aee"</span>,</span><br><span class="line">        <span class="string">"doctype"</span>: <span class="string">"json"</span>,</span><br><span class="line">        <span class="string">"version"</span>: <span class="string">"2.1"</span>,</span><br><span class="line">        <span class="string">"keyfrom"</span>: <span class="string">"fanyi.web"</span>,</span><br><span class="line">        <span class="string">"action"</span>: <span class="string">"FY_BY_REALTlME"</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.post(url=url,headers = header,data=formdata).content.decode()</span><br><span class="line">    <span class="comment"># "tgt":"hello"</span></span><br><span class="line">    pat1=re.compile(<span class="string">'"tgt":"(.*?)"'</span>)</span><br><span class="line">    data = pat1.findall(response)</span><br><span class="line">    str1=<span class="string">""</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">        str1+=i</span><br><span class="line">    <span class="keyword">return</span> str1</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    data = pd.read_csv(<span class="string">"./microwave.csv"</span>, encoding=<span class="string">'UTF-8'</span>, error_bad_lines=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> data.review_headline:</span><br><span class="line">        info = fanyi(i)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">"./microwave.txt"</span>,<span class="string">'a+'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(str(info)+<span class="string">'\n'</span>)</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li></ol></li><li>输出的数据如下<br><img src="/2020/03/02/Pachong_Fanyi/%E5%9B%BE%E7%89%876.png" alt></li></ul><h3 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h3><p>转载请注明出处，禁止一切商业用途，目的：仅供学习与使用翻译端口没有任何其他目的。欢迎各位大佬指正错误，有问题请在下方留言，或者点击左边的微信/QQ加我进行联系。看到后会第一时间进行回复。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;写这篇文档的主要初衷是因为：因为前几天的美赛，由于我们要通过评论的内容找到该评论的情感倾向，但是由于Excel内的翻译功能支持不了大规模的数据进行翻译，然后其他的一些在线翻译的软件需要付费，所以自己写了一个端口用于翻译。（本篇文章内容的翻译仅支持小规模数据，做到及翻及储，大规模数模进行多次翻译还是会出现无连接的情况）&lt;/p&gt;
    
    </summary>
    
    
      <category term="爬虫" scheme="http://GaoBaiiBai.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="爬虫" scheme="http://GaoBaiiBai.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="端口" scheme="http://GaoBaiiBai.com/tags/%E7%AB%AF%E5%8F%A3/"/>
    
      <category term="翻译" scheme="http://GaoBaiiBai.com/tags/%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
</feed>
